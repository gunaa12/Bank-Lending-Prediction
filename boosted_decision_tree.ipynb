{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f7c9f64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164132/1305700499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2fd40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(42, 84)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(84, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "494d9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # boosted decision tree\n",
    "# class BoostedDecisionTree:\n",
    "#     def __init__(self, num_of_trees, max_depth=1):\n",
    "#         self.trees = []\n",
    "#         self.weights = []\n",
    "#         self.num_of_trees = num_of_trees\n",
    "#         self.max_depth = max_depth\n",
    "\n",
    "#     # try and see how random forest compares\n",
    "#     # try using class weights here\n",
    "#     # try gini and see training time change\n",
    "#     def fit(self, X, y, init_weights):\n",
    "#         N = X.shape[0]\n",
    "#         w = init_weights\n",
    "\n",
    "#         for m in range(self.num_of_trees):\n",
    "#             tree = DecisionTreeClassifier(max_depth=self.max_depth, criterion=\"gini\")\n",
    "\n",
    "#             norm_w = np.exp(w)\n",
    "#             norm_w /= norm_w.sum()\n",
    "            \n",
    "#             tree.fit(X, y, sample_weight=norm_w)\n",
    "#             yhat = tree.predict(X)\n",
    "\n",
    "#             eps = norm_w.dot(yhat != y) + 1e-20\n",
    "#             alpha = (np.log(1 - eps) - np.log(eps)) / 2\n",
    "\n",
    "#             w = w - alpha * y * yhat\n",
    "\n",
    "#             self.trees.append(tree)\n",
    "#             self.weights.append(alpha)\n",
    "\n",
    "#     def predict(self,X):\n",
    "#         # try fixing this as current predictions arounf 48-52% are overwritten\n",
    "#         y = np.zeros(X.shape[0])\n",
    "#         for (tree, alpha) in zip(self.trees, self.weights):\n",
    "#             y = y + alpha * tree.predict(X)\n",
    "#         y = y - y.min()\n",
    "#         y = [round(num) for num in y]\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddaf6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    776024\n",
       "0    191895\n",
       "Name: loan_paid, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the data\n",
    "df = pd.read_csv('data/train_preprocessed_data.csv')\n",
    "pd.set_option('max_columns', None)\n",
    "df['loan_paid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2339ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data\n",
    "y_train = df['loan_paid'].to_numpy()\n",
    "x_train = df.drop(columns=['loan_paid']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a107d571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# fixing numpy conversion issues\n",
    "x_train[np.isinf(x_train)] = 0\n",
    "print(np.where(np.isinf(x_train)))\n",
    "\n",
    "print(np.where(np.isinf(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd60eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "# lg = LogisticRegression(random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8160532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2, n_estimators=50, subsample=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest model\n",
    "rfc1 = GradientBoostingClassifier(n_estimators=50, max_depth=2, subsample=1)\n",
    "rfc1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0950b6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2, n_estimators=150, subsample=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc2 = GradientBoostingClassifier(n_estimators=150, max_depth=2, subsample=1)\n",
    "rfc2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c173720c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164132/2816684762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/apps/cent7/jupyterhub/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m/apps/cent7/jupyterhub/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m/apps/cent7/jupyterhub/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/cent7/jupyterhub/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \"\"\"\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1253\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/cent7/jupyterhub/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfc3 = GradientBoostingClassifier(n_estimators=300, max_depth=2, subsample=1)\n",
    "rfc3.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2954e07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2, n_estimators=500, subsample=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc4 = GradientBoostingClassifier(n_estimators=500, max_depth=2, subsample=1)\n",
    "rfc4.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = GradientBoostingClassifier(n_estimators=1000, max_depth=2, subsample=1)\n",
    "rfc5.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54b09f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting stored cluster_count and k_means model\n",
    "# with open('models/k_means.pickle', 'rb') as handle:\n",
    "#     k_means = pickle.load(handle)\n",
    "    \n",
    "# with open('data/cluster_count.pickle', 'rb') as handle:\n",
    "#     cluster_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10b52e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generating init_weights\n",
    "# init_weights = []\n",
    "# total_count = sum(cluster_count)\n",
    "# cluster_pred = k_means.predict(x_train)\n",
    "\n",
    "# for pred in cluster_pred:\n",
    "#     init_weights.append(cluster_count[pred] / total_count)\n",
    "\n",
    "# init_weights = np.array(init_weights)\n",
    "# init_weights = init_weights / sum(init_weights)\n",
    "# init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c0bd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the data\n",
    "# # maybe overfitting? reduce # of trees necessary\n",
    "# model = BoostedDecisionTree(250, 1)\n",
    "# model.fit(x_train, y_train, init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d5dc0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting validation input\n",
    "x_val = pd.read_csv('data/predict_preprocessed_data.csv')\n",
    "x_val_id = x_val['ID']\n",
    "x_val = x_val.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "296348a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([140519]), array([12]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to np array\n",
    "x_val = x_val.to_numpy()\n",
    "print(np.where(np.isinf(x_val)))\n",
    "x_val[np.isinf(x_val)] = 0\n",
    "np.where(np.isinf(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bef91d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicting using logistic regression\n",
    "# pred_probs = lg.predict(x_val)\n",
    "# pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8079f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = GradientBoostingRegressor(n_estimators=500, max_depth=3, learning_rate=0.1)\n",
    "DT.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c23ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = DT.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9e0b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for p in pred:\n",
    "    if (p >= .5):\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afad14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802887\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for p, c in zip(preds, y_train):\n",
    "    if p == c:\n",
    "        correct = correct + 1\n",
    "print(correct / y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1849e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicting using random forest\n",
    "# pred_probs = rfc.predict(x_val)\n",
    "# zero = min(pred_probs)\n",
    "# pred = []\n",
    "# for prob in pred_probs:\n",
    "#     if (prob == zero):\n",
    "#         pred.append(0)\n",
    "#     else:\n",
    "#         pred.append(1)\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c71e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Net()\n",
    "# net.fit(x_train, y_train)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=.001)\n",
    "\n",
    "# for epoch in 500:\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     y_pred = net(x_train)\n",
    "#     train_loss = my_NLLloss(y_pred, y_train)\n",
    "\n",
    "#     y_pred = net(x_val)\n",
    "#     val_loss = my_NLLloss(y_pred, y_val)\n",
    "\n",
    "#     train_loss.backward()        \n",
    "#     optimizer.step()\n",
    "#     # <<< END YOUR CODE\n",
    "\n",
    "#     # DO NOT MODIFY THE BELOW\n",
    "#     train_losses.append(train_loss.item())\n",
    "#     val_losses.append(val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ed50235",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc2.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b639bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating submission\n",
    "submission = pd.DataFrame()\n",
    "submission['ID'] = x_val_id\n",
    "submission['loan_paid'] = pred\n",
    "submission.to_csv('submissions/pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2ce5bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GradientBoostingClassifier(max_depth=2, n_estimators=500, subsample=1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [rfc4]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c715597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8043710269144422\n"
     ]
    }
   ],
   "source": [
    "for rfc in r:\n",
    "    print(rfc.score(x_train, y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
